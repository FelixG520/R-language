# 回归，通常指用一个或多个预测变量，也称自变量或者解释变量，来预测响应变量，也称因变量、标效变量或者结果变量的方法
# 回归分析主要用于分析自变量对因变量的影响
# 重点是：如何建立模型、抽象出数学公式、哪些因素与模型有关、需要利用多少样品、模型的准确率有多高、在实际运用中还是否有效？

# 最简单的线性回归：普通最小二乘回归法（OLS）
?lm
#可以使用lm()函数来进行线性回归分析，lm是linear model，线性回归模型的简称
#这个函数的格式是：
# lm(formula, data, subset, weights, na.action, method = "qr", model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...)
# formula：是要进行拟合的模型形式，写成一个公式，例如，y ~ ax+b
# data：是要使用的数据集，是数据框的格式

women
plot(women$height,women$weight)
#一般在回归分析中，都喜欢用fit这个变量名来定义结果，寻找回归模型的过程被称为拟合
#如果后面data参数中指定了数据集，那么前面公式中的变量就可以直接写变量名字（注意，因变量在波浪线左边，自变量在右边）
fit <- lm(weight ~ height, data=women)
#可以使用summary()函数查看详细的分析结果：
summary(fit)
#call这一列，是列出使用的回归的公式。
#residuals，表示残差，残差是真实值和预测值之间的差，例如数据第一行，真实的值是58，将58代入预测公式，得出的预测值y，y与58之间的差值就是残差，
#残差给出了四个值，最小值、最大值、中位值、四分之一的值、四分之三的值，这四个值越小，说明预测模型越精确。
#Coefficients：系数项，
#intercept：截距项（当x等于0时，与y轴的相交点）
#Estimate是项系数的值，
#pr就是pvalue，是假设x与y不相关时候的概率，这个值也是小于0.05比较好，
#residual standard error残差标准误，表示残差的标准误差，这个也是越小越好。
#Multiple R-squared:  0.991,	Adjusted R-squared:  0.9903 这两个值称为R方判定系数，是衡量模型拟合质量的指标，
#它是表示回归模型所能解释的响应变量的方差比例，比如此处，就代表这个模型可以解释99.1%的数据，只有0.9%的数据不符合这个模型，取值在0-1之间，值越大于好。
#F-statistic（F统计量），这个值说明模型是否显著，也是用pvalue来衡量，也是值越小越好。
women$weight
fitted(fit)
#在线性回归的结果中，一般先看F统计量，如果F统计量不显著（pvalue不小于0.05），那么这个模型就没有价值了，需要重新进行拟合，如果小于0.05，再看R方差，模型能解释多少变量